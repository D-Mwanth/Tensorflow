{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMo4uqgsrBZF7CWesarjYA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madrinmarison/Deep_Learning/blob/main/Transfer_Learning_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with Tensorflow Part 1: Features Extraction\n",
        "\n",
        "Transfer learning - leveraging an existing working model's architecture and learned patterns  for our own problem.\n",
        "\n",
        "Two main benefits:\n",
        "1. Can leverage an existing neural network architecture proven to work on problem similar to our own.\n",
        "2. Can laverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adpt those patterns to our own data."
      ],
      "metadata": {
        "id": "5sMtdVjSEhNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm you're connected to GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8EEG3c5oQ5jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get data (10% of 10 food classes from Food101)\n",
        "import zipfile\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Zxo5sNqERK8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Becoming one with the data"
      ],
      "metadata": {
        "id": "-BeaJXfJuvy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder\n",
        "import os\n",
        "\n",
        "# Walk through 10% data directory and list number of files.\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} files in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "2Wo3LcoLSqpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loaders (preparing the data)\n",
        "Use the `ImageDataGenetator` class to load in our images in batches.\n",
        "\n",
        "- Import the class from the `tensorflow.keras.preprocessing.image` module\n",
        "- Instatiate an instance of the class and pass the class the corect attributes you would like to be incorporated while loading the image\n",
        "- call a `flow_from_directoty` method and pass an appropriate parameters"
      ],
      "metadata": {
        "id": "TGpSHvRMUNxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1 / 255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1 / 255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                  target_size=IMAGE_SIZE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode = \"categorical\")\n",
        "\n",
        "print(\"Test images:\")\n",
        "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
        "                                                        target_size=IMAGE_SIZE,\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        class_mode = \"categorical\")\n",
        "\n"
      ],
      "metadata": {
        "id": "JOFLJcy5VLu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## St up callbacks (things to run whislt our model train)\n",
        "\n",
        "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of te most popular callbacks are:\n",
        "* Tracking an experiment with *tensorboard callback*.\n",
        "* Model checkpoint with the ModelCheckpointcallback\n",
        "* Stopping the model from training (before it trains for too long and overfits) with EarlyStopping callback"
      ],
      "metadata": {
        "id": "KPkVq4yeYP2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionized because we want to create a new one for each model)\n",
        "import datetime\n",
        "\n",
        "def creat_tensorbord_callback(dir_name, experiment_name):\n",
        "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "    print(f\"Saving TensorBoard log file to: {log_dir}\")\n",
        "    return tensorboard_callback"
      ],
      "metadata": {
        "id": "KvYxJZpGceJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can customize the directory where your TensorBoard logs (model traing metrics) get saved to wherever you like.\n",
        "\n",
        "The `log_dir` parameter we have created above is only optional."
      ],
      "metadata": {
        "id": "ML_2LC-igHT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used Tensorflow to create our models layer by layer from the scratch.\n",
        "\n",
        "Now we are going to do a similar process the majority of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access a pre-trained model on: https://tfhub.dev/\n",
        "\n",
        "Browsing the TensorFlow Hub page and sorting for image classification, we found the feature vector model link provided [here](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1)."
      ],
      "metadata": {
        "id": "sjYPz95UfsbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the following two models\n",
        "resmet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "efficient_net = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "sVHjOR76ihPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import depedencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "5cM3Sk4X-Qfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to create a model from url\n",
        "def create_model(model_url, num_classes = 10):\n",
        "    \"\"\"\n",
        "    Takes TensorFlow Hub URL and creates keras Sequential model with it.\n",
        "\n",
        "    Args:\n",
        "        model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "        num_classes (int): Number of output neurons in the output layer,\n",
        "            should be equal to number of target classes, defult = 10\n",
        "    \n",
        "    Returns:\n",
        "        An uncompiled keras Sequential model with model URL as feature extractor\n",
        "        layer and Dense output layer with num_classes output neuron\n",
        "    \"\"\"\n",
        "    # Download the pretrained model and save it as a keras layer\n",
        "    feature_extract_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable = False,\n",
        "                                           name = \"feature_extraction_layer\",\n",
        "                                           input_shape = IMAGE_SIZE + (3,)) # Freeze an already learned patterns\n",
        "    # Creatae our own model\n",
        "    model = tf.keras.Sequential([\n",
        "        feature_extract_layer,\n",
        "        layers.Dense(num_classes, activation = \"softmax\", name = \"output_layer\")\n",
        "    ])\n",
        "    return model\n",
        "    "
      ],
      "metadata": {
        "id": "FRIiVLXI-2As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and testing Resnet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "Rw11TnnmEu__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the resenet model\n",
        "resnet_model = create_model(resmet_url,\n",
        "                             num_classes = train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "l0YarvX6FIZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "uVwUwZvMKZPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile our resenet model\n",
        "resnet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                     optimizer = tf.keras.optimizers.Adam(),\n",
        "                     metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "1_634oVxKuCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs = 5,\n",
        "                                  steps_per_epoch = len(train_data_10_percent),\n",
        "                                  validation_data = test_data_10_percent,\n",
        "                                  validation_steps = len(test_data_10_percent),\n",
        "                                  callbacks = [creat_tensorbord_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                                         experiment_name = \"resnet_v2_50\")])\n",
        "                                  "
      ],
      "metadata": {
        "id": "vkQ9rqA0MB2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model, transfer learning feature extractor, outperformed all the previuos model we build from the scracth and in a quicker training time with only 10% of the training example."
      ],
      "metadata": {
        "id": "MVvLmKn-RNkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qnA4VP5SX5VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loss curve plotting function\n",
        "# Tidbit: you could put a function like this into a script called \"helper.py\" and import it whenever needed... upload to git\n",
        "def plot_loss_curves(history):\n",
        "    \"\"\"\n",
        "    Returns seperate loss curves for training and validation metrics\n",
        "    Args:\n",
        "        history: TensorFlow History object.\n",
        "\n",
        "    Returns:\n",
        "        Plots of training/validation loss and accuracy metrics.\n",
        "    \"\"\"\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    \n",
        "    accuracy = history.history[\"accuracy\"]\n",
        "    val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "    epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "    # plot loss\n",
        "    plt.plot(epochs, loss, label = \"training_loss\")\n",
        "    plt.plot(epochs, val_loss, label = \"val_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend();\n",
        "\n",
        "    # plot accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
        "    plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend();"
      ],
      "metadata": {
        "id": "yOB3bVbSNTWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "id": "8s58iUuxVtWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "3XAgl_ZnX1fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create EfficientNetB0 Feature extracor model\n",
        "efficient_model = create_model(model_url = efficient_net,\n",
        "                               num_classes = train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile the model\n",
        "efficient_model.compile(loss = \"categorical_crossentropy\",\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics = [\"accuracy\"])\n",
        "\n",
        "# Create the model\n",
        "efficient_history = efficient_model.fit(train_data_10_percent,\n",
        "                                        epochs = 5,\n",
        "                                        steps_per_epoch = len(train_data_10_percent),\n",
        "                                        validation_data = test_data_10_percent,\n",
        "                                        validation_steps = len(test_data_10_percent),\n",
        "                                        callbacks = [creat_tensorbord_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                                         experiment_name = \"efficientnetb0\")])"
      ],
      "metadata": {
        "id": "MdOCPJgMbwcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss and accuracy curves\n",
        "plot_loss_curves(efficient_history)"
      ],
      "metadata": {
        "id": "rFTCKbPGeW5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create EfficientNetB0 Feature extracot model\n",
        "efficient_model_1 = create_model(model_url = efficient_net,\n",
        "                               num_classes = train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile the model\n",
        "efficient_model_1.compile(loss = \"categorical_crossentropy\",\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics = [\"accuracy\"])\n",
        "\n",
        "# Create the model\n",
        "efficient_history_1 = efficient_model_1.fit(train_data_10_percent,\n",
        "                                        epochs = 28,\n",
        "                                        steps_per_epoch = len(train_data_10_percent),\n",
        "                                        validation_data = test_data_10_percent,\n",
        "                                        validation_steps = len(test_data_10_percent))\n",
        "                                        #callbacks = [creat_tensorbord_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                                       #  experiment_name = \"efficientnetb0\")])"
      ],
      "metadata": {
        "id": "Xq8avheXexRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different types of transfer learning\n",
        "\n",
        "* **\"As is\" transfer learning:** - using an existing model with no changes what so ever (e.g. using ImageNet model on 1000 image classes, on of your own problem)\n",
        "* **Feature extraction\" transefer learning:** -  Use pre-learned patterns of an existing model (e.g using EfficientB0 trained on ImageNet) and adjust the output layer for your probelem (e.g. 1000 classes --> 10 classes of food)\n",
        "* **\"Fine-tunning\" transfer learning**"
      ],
      "metadata": {
        "id": "YcJgEzBkjWZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing model's results using TensorBoard\n",
        "> 🔑 **Note:** When you upload things to TensorBoard.dev, your experiments are public. So if you're running private experiment (things you don't want others to see) do not upload them to TensorBoard.dev."
      ],
      "metadata": {
        "id": "xyRCP_3TmvHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload TensorBoadr dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "--name \"EfficientB0 vs ResNet50V2\" \\\n",
        "--description \"Compairing two different TF Hub feature extraction model architecture using 10% of the training data\" \\\n",
        "--one_shot"
      ],
      "metadata": {
        "id": "nIVtYyoMmx87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our TensorFlow experiment are uploaded pulically [here](https://tensorboard.dev/experiment/WpVXZHr7TMqWqpVJtz9ZAg/)"
      ],
      "metadata": {
        "id": "7LHCrqmom7x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check out what TensorBoard experiments you have\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "bpPbu5fMm3xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete an experiment from TensorBoard\n",
        "# !tensorboard dev delete --experiment_id WpVXZHr7TMqWqpVJtz9ZAg"
      ],
      "metadata": {
        "id": "iepcPKLbnAMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirn the deletion by rechecking what experiments you have left\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "hLKw2pclnLdP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}